15:4: not a valid test operator:  
15:4: not a valid test operator: 12.4
21:4: not a valid test operator: (
21:4: not a valid test operator: 550.90.07
W0120 19:30:55.806000 92925 site-packages/torch/distributed/run.py:803] 
W0120 19:30:55.806000 92925 site-packages/torch/distributed/run.py:803] *****************************************
W0120 19:30:55.806000 92925 site-packages/torch/distributed/run.py:803] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0120 19:30:55.806000 92925 site-packages/torch/distributed/run.py:803] *****************************************
You set `add_prefix_space`. The tokenizer needs to be converted from the slow tokenizers
You set `add_prefix_space`. The tokenizer needs to be converted from the slow tokenizers
You set `add_prefix_space`. The tokenizer needs to be converted from the slow tokenizers
You set `add_prefix_space`. The tokenizer needs to be converted from the slow tokenizers
You set `add_prefix_space`. The tokenizer needs to be converted from the slow tokenizers
You set `add_prefix_space`. The tokenizer needs to be converted from the slow tokenizers
You set `add_prefix_space`. The tokenizer needs to be converted from the slow tokenizers
You set `add_prefix_space`. The tokenizer needs to be converted from the slow tokenizers
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:00,  3.18it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:00,  3.15it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:00,  3.15it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:00,  3.15it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:00,  3.15it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:00,  3.15it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:00,  3.15it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:00,  3.15it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:00<00:00,  2.92it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:00<00:00,  2.92it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:00<00:00,  2.91it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:00<00:00,  2.92it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:00<00:00,  2.92it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:00<00:00,  2.92it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:00<00:00,  2.92it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:00<00:00,  2.91it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:00<00:00,  3.08it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:00<00:00,  3.08it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:00<00:00,  3.08it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:00<00:00,  3.08it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:00<00:00,  3.08it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:00<00:00,  3.08it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:00<00:00,  3.08it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:00<00:00,  3.08it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:01<00:00,  3.42it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:01<00:00,  3.42it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:01<00:00,  3.42it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:01<00:00,  3.42it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:01<00:00,  3.42it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:01<00:00,  3.42it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:01<00:00,  3.27it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:01<00:00,  3.27it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:01<00:00,  3.27it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:01<00:00,  3.42it/s]


Loading checkpoint shards: 100%|██████████| 4/4 [00:01<00:00,  3.27it/s]
Loading checkpoint shards: 100%|██████████| 4/4 [00:01<00:00,  3.27it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:01<00:00,  3.27it/s]

Loading checkpoint shards: 100%|██████████| 4/4 [00:01<00:00,  3.27it/s]
Loading checkpoint shards: 100%|██████████| 4/4 [00:01<00:00,  3.42it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:01<00:00,  3.27it/s]
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:11<00:23, 11.73s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:11<00:23, 11.99s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:11<00:23, 11.99s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:11<00:23, 11.99s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:11<00:23, 11.98s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:11<00:23, 11.99s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:11<00:23, 11.99s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:11<00:23, 11.99s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:23<00:11, 11.79s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:23<00:11, 11.92s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:23<00:11, 11.92s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:23<00:11, 11.92s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:23<00:11, 11.92s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:23<00:11, 11.92s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:23<00:11, 11.92s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:23<00:11, 11.97s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:27<00:00,  7.95s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:27<00:00,  9.01s/it]
Loading checkpoint shards: 100%|██████████| 3/3 [00:27<00:00,  7.95s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:27<00:00,  7.96s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:27<00:00,  7.95s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:27<00:00,  7.96s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:27<00:00,  7.95s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:27<00:00,  7.96s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:27<00:00,  7.99s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:27<00:00,  9.03s/it]
Loading checkpoint shards: 100%|██████████| 3/3 [00:27<00:00,  9.03s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:27<00:00,  9.03s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:27<00:00,  9.03s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:27<00:00,  9.03s/it]

Loading checkpoint shards: 100%|██████████| 3/3 [00:27<00:00,  9.03s/it]


Loading checkpoint shards: 100%|██████████| 3/3 [00:27<00:00,  9.03s/it]
01/20/2026 19:32:14 - INFO - trainer - Accelerator state: 
Distributed environment: DEEPSPEED  Backend: nccl
Num processes: 8
Process index: 4
Local process index: 4
Device: cuda:4

Mixed precision type: bf16
ds_config: {'bf16': {'enabled': True}, 'optimizer': {'type': 'AdamW', 'params': {'lr': 'auto', 'weight_decay': 'auto', 'torch_adam': True, 'adam_w_mode': True}}, 'scheduler': {'type': 'WarmupDecayLR', 'params': {'warmup_min_lr': 'auto', 'warmup_max_lr': 'auto', 'warmup_num_steps': 'auto', 'total_num_steps': 'auto'}}, 'zero_optimization': {'stage': 2, 'allgather_partitions': True, 'allgather_bucket_size': 200000000.0, 'overlap_comm': True, 'reduce_scatter': True, 'reduce_bucket_size': 500000000.0, 'contiguous_gradients': True}, 'gradient_accumulation_steps': 1, 'train_micro_batch_size_per_gpu': 1, 'train_batch_size': 'auto', 'gradient_clipping': 'auto', 'steps_per_print': inf, 'wall_clock_breakdown': False, 'fp16': {'enabled': False}}

01/20/2026 19:32:14 - INFO - trainer - Accelerator state: 
Distributed environment: DEEPSPEED  Backend: nccl
Num processes: 8
Process index: 3
Local process index: 3
Device: cuda:3

Mixed precision type: bf16
ds_config: {'bf16': {'enabled': True}, 'optimizer': {'type': 'AdamW', 'params': {'lr': 'auto', 'weight_decay': 'auto', 'torch_adam': True, 'adam_w_mode': True}}, 'scheduler': {'type': 'WarmupDecayLR', 'params': {'warmup_min_lr': 'auto', 'warmup_max_lr': 'auto', 'warmup_num_steps': 'auto', 'total_num_steps': 'auto'}}, 'zero_optimization': {'stage': 2, 'allgather_partitions': True, 'allgather_bucket_size': 200000000.0, 'overlap_comm': True, 'reduce_scatter': True, 'reduce_bucket_size': 500000000.0, 'contiguous_gradients': True}, 'gradient_accumulation_steps': 1, 'train_micro_batch_size_per_gpu': 1, 'train_batch_size': 'auto', 'gradient_clipping': 'auto', 'steps_per_print': inf, 'wall_clock_breakdown': False, 'fp16': {'enabled': False}}

01/20/2026 19:32:14 - INFO - trainer - Accelerator state: 
Distributed environment: DEEPSPEED  Backend: nccl
Num processes: 8
Process index: 5
Local process index: 5
Device: cuda:5

Mixed precision type: bf16
ds_config: {'bf16': {'enabled': True}, 'optimizer': {'type': 'AdamW', 'params': {'lr': 'auto', 'weight_decay': 'auto', 'torch_adam': True, 'adam_w_mode': True}}, 'scheduler': {'type': 'WarmupDecayLR', 'params': {'warmup_min_lr': 'auto', 'warmup_max_lr': 'auto', 'warmup_num_steps': 'auto', 'total_num_steps': 'auto'}}, 'zero_optimization': {'stage': 2, 'allgather_partitions': True, 'allgather_bucket_size': 200000000.0, 'overlap_comm': True, 'reduce_scatter': True, 'reduce_bucket_size': 500000000.0, 'contiguous_gradients': True}, 'gradient_accumulation_steps': 1, 'train_micro_batch_size_per_gpu': 1, 'train_batch_size': 'auto', 'gradient_clipping': 'auto', 'steps_per_print': inf, 'wall_clock_breakdown': False, 'fp16': {'enabled': False}}

01/20/2026 19:32:14 - INFO - trainer - Accelerator state: 
Distributed environment: DEEPSPEED  Backend: nccl
Num processes: 8
Process index: 2
Local process index: 2
Device: cuda:2

Mixed precision type: bf16
ds_config: {'bf16': {'enabled': True}, 'optimizer': {'type': 'AdamW', 'params': {'lr': 'auto', 'weight_decay': 'auto', 'torch_adam': True, 'adam_w_mode': True}}, 'scheduler': {'type': 'WarmupDecayLR', 'params': {'warmup_min_lr': 'auto', 'warmup_max_lr': 'auto', 'warmup_num_steps': 'auto', 'total_num_steps': 'auto'}}, 'zero_optimization': {'stage': 2, 'allgather_partitions': True, 'allgather_bucket_size': 200000000.0, 'overlap_comm': True, 'reduce_scatter': True, 'reduce_bucket_size': 500000000.0, 'contiguous_gradients': True}, 'gradient_accumulation_steps': 1, 'train_micro_batch_size_per_gpu': 1, 'train_batch_size': 'auto', 'gradient_clipping': 'auto', 'steps_per_print': inf, 'wall_clock_breakdown': False, 'fp16': {'enabled': False}}

01/20/2026 19:32:14 - INFO - trainer - Accelerator state: 
Distributed environment: DEEPSPEED  Backend: nccl
Num processes: 8
Process index: 7
Local process index: 7
Device: cuda:7

Mixed precision type: bf16
ds_config: {'bf16': {'enabled': True}, 'optimizer': {'type': 'AdamW', 'params': {'lr': 'auto', 'weight_decay': 'auto', 'torch_adam': True, 'adam_w_mode': True}}, 'scheduler': {'type': 'WarmupDecayLR', 'params': {'warmup_min_lr': 'auto', 'warmup_max_lr': 'auto', 'warmup_num_steps': 'auto', 'total_num_steps': 'auto'}}, 'zero_optimization': {'stage': 2, 'allgather_partitions': True, 'allgather_bucket_size': 200000000.0, 'overlap_comm': True, 'reduce_scatter': True, 'reduce_bucket_size': 500000000.0, 'contiguous_gradients': True}, 'gradient_accumulation_steps': 1, 'train_micro_batch_size_per_gpu': 1, 'train_batch_size': 'auto', 'gradient_clipping': 'auto', 'steps_per_print': inf, 'wall_clock_breakdown': False, 'fp16': {'enabled': False}}

Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
01/20/2026 19:32:14 - INFO - trainer - Initialized Trainer
01/20/2026 19:32:14 - INFO - trainer - Accelerator state: 
Distributed environment: DEEPSPEED  Backend: nccl
Num processes: 8
Process index: 0
Local process index: 0
Device: cuda:0

Mixed precision type: bf16
ds_config: {'bf16': {'enabled': True}, 'optimizer': {'type': 'AdamW', 'params': {'lr': 'auto', 'weight_decay': 'auto', 'torch_adam': True, 'adam_w_mode': True}}, 'scheduler': {'type': 'WarmupDecayLR', 'params': {'warmup_min_lr': 'auto', 'warmup_max_lr': 'auto', 'warmup_num_steps': 'auto', 'total_num_steps': 'auto'}}, 'zero_optimization': {'stage': 2, 'allgather_partitions': True, 'allgather_bucket_size': 200000000.0, 'overlap_comm': True, 'reduce_scatter': True, 'reduce_bucket_size': 500000000.0, 'contiguous_gradients': True}, 'gradient_accumulation_steps': 1, 'train_micro_batch_size_per_gpu': 1, 'train_batch_size': 'auto', 'gradient_clipping': 'auto', 'steps_per_print': inf, 'wall_clock_breakdown': False, 'fp16': {'enabled': False}}

01/20/2026 19:32:14 - INFO - trainer - Initializing models
01/20/2026 19:32:14 - INFO - trainer - Initializing dataset and dataloader
01/20/2026 19:32:14 - INFO - trainer - Accelerator state: 
Distributed environment: DEEPSPEED  Backend: nccl
Num processes: 8
Process index: 6
Local process index: 6
Device: cuda:6

Mixed precision type: bf16
ds_config: {'bf16': {'enabled': True}, 'optimizer': {'type': 'AdamW', 'params': {'lr': 'auto', 'weight_decay': 'auto', 'torch_adam': True, 'adam_w_mode': True}}, 'scheduler': {'type': 'WarmupDecayLR', 'params': {'warmup_min_lr': 'auto', 'warmup_max_lr': 'auto', 'warmup_num_steps': 'auto', 'total_num_steps': 'auto'}}, 'zero_optimization': {'stage': 2, 'allgather_partitions': True, 'allgather_bucket_size': 200000000.0, 'overlap_comm': True, 'reduce_scatter': True, 'reduce_bucket_size': 500000000.0, 'contiguous_gradients': True}, 'gradient_accumulation_steps': 1, 'train_micro_batch_size_per_gpu': 1, 'train_batch_size': 'auto', 'gradient_clipping': 'auto', 'steps_per_print': inf, 'wall_clock_breakdown': False, 'fp16': {'enabled': False}}

01/20/2026 19:32:14 - INFO - trainer - Accelerator state: 
Distributed environment: DEEPSPEED  Backend: nccl
Num processes: 8
Process index: 1
Local process index: 1
Device: cuda:1

Mixed precision type: bf16
ds_config: {'bf16': {'enabled': True}, 'optimizer': {'type': 'AdamW', 'params': {'lr': 'auto', 'weight_decay': 'auto', 'torch_adam': True, 'adam_w_mode': True}}, 'scheduler': {'type': 'WarmupDecayLR', 'params': {'warmup_min_lr': 'auto', 'warmup_max_lr': 'auto', 'warmup_num_steps': 'auto', 'total_num_steps': 'auto'}}, 'zero_optimization': {'stage': 2, 'allgather_partitions': True, 'allgather_bucket_size': 200000000.0, 'overlap_comm': True, 'reduce_scatter': True, 'reduce_bucket_size': 500000000.0, 'contiguous_gradients': True}, 'gradient_accumulation_steps': 1, 'train_micro_batch_size_per_gpu': 1, 'train_batch_size': 'auto', 'gradient_clipping': 'auto', 'steps_per_print': inf, 'wall_clock_breakdown': False, 'fp16': {'enabled': False}}

[rank7]: Traceback (most recent call last):
[rank7]:   File "/mnt/petrelfs/zhangsiyu/4dgen/CogVideo/finetune/train.py", line 19, in <module>
[rank7]:     main()
[rank7]:   File "/mnt/petrelfs/zhangsiyu/4dgen/CogVideo/finetune/train.py", line 15, in main
[rank7]:     trainer.fit()
[rank7]:   File "/mnt/petrelfs/zhangsiyu/4dgen/CogVideo/finetune/trainer.py", line 673, in fit
[rank7]:     self.prepare_dataset()
[rank7]:   File "/mnt/petrelfs/zhangsiyu/4dgen/CogVideo/finetune/trainer.py", line 204, in prepare_dataset
[rank7]:     tmp_data_loader = self.accelerator.prepare_data_loader(tmp_data_loader)
[rank7]:   File "/mnt/petrelfs/zhangsiyu/miniconda3/envs/cogvideox/lib/python3.10/site-packages/accelerate/accelerator.py", line 2715, in prepare_data_loader
[rank7]:     prepared_data_loader = prepare_data_loader(
[rank7]:   File "/mnt/petrelfs/zhangsiyu/miniconda3/envs/cogvideox/lib/python3.10/site-packages/accelerate/data_loader.py", line 1205, in prepare_data_loader
[rank7]:     from datasets import IterableDataset as DatasetsIterableDataset
[rank7]: ImportError: cannot import name 'IterableDataset' from 'datasets' (/mnt/petrelfs/zhangsiyu/4dgen/CogVideo/finetune/datasets/__init__.py)
01/20/2026 19:32:42 - INFO - trainer - Precomputing latent for video and prompt embedding ...
[rank2]: Traceback (most recent call last):
[rank2]:   File "/mnt/petrelfs/zhangsiyu/4dgen/CogVideo/finetune/train.py", line 19, in <module>
[rank2]:     main()
[rank2]:   File "/mnt/petrelfs/zhangsiyu/4dgen/CogVideo/finetune/train.py", line 15, in main
[rank2]:     trainer.fit()
[rank2]:   File "/mnt/petrelfs/zhangsiyu/4dgen/CogVideo/finetune/trainer.py", line 673, in fit
[rank2]:     self.prepare_dataset()
[rank2]:   File "/mnt/petrelfs/zhangsiyu/4dgen/CogVideo/finetune/trainer.py", line 204, in prepare_dataset
[rank2]:     tmp_data_loader = self.accelerator.prepare_data_loader(tmp_data_loader)
[rank2]:   File "/mnt/petrelfs/zhangsiyu/miniconda3/envs/cogvideox/lib/python3.10/site-packages/accelerate/accelerator.py", line 2715, in prepare_data_loader
[rank2]:     prepared_data_loader = prepare_data_loader(
[rank2]:   File "/mnt/petrelfs/zhangsiyu/miniconda3/envs/cogvideox/lib/python3.10/site-packages/accelerate/data_loader.py", line 1205, in prepare_data_loader
[rank2]:     from datasets import IterableDataset as DatasetsIterableDataset
[rank2]: ImportError: cannot import name 'IterableDataset' from 'datasets' (/mnt/petrelfs/zhangsiyu/4dgen/CogVideo/finetune/datasets/__init__.py)
[rank6]: Traceback (most recent call last):
[rank6]:   File "/mnt/petrelfs/zhangsiyu/4dgen/CogVideo/finetune/train.py", line 19, in <module>
[rank6]:     main()
[rank6]:   File "/mnt/petrelfs/zhangsiyu/4dgen/CogVideo/finetune/train.py", line 15, in main
[rank6]:     trainer.fit()
[rank6]:   File "/mnt/petrelfs/zhangsiyu/4dgen/CogVideo/finetune/trainer.py", line 673, in fit
[rank6]:     self.prepare_dataset()
[rank6]:   File "/mnt/petrelfs/zhangsiyu/4dgen/CogVideo/finetune/trainer.py", line 204, in prepare_dataset
[rank6]:     tmp_data_loader = self.accelerator.prepare_data_loader(tmp_data_loader)
[rank6]:   File "/mnt/petrelfs/zhangsiyu/miniconda3/envs/cogvideox/lib/python3.10/site-packages/accelerate/accelerator.py", line 2715, in prepare_data_loader
[rank6]:     prepared_data_loader = prepare_data_loader(
[rank6]:   File "/mnt/petrelfs/zhangsiyu/miniconda3/envs/cogvideox/lib/python3.10/site-packages/accelerate/data_loader.py", line 1205, in prepare_data_loader
[rank6]:     from datasets import IterableDataset as DatasetsIterableDataset
[rank6]: ImportError: cannot import name 'IterableDataset' from 'datasets' (/mnt/petrelfs/zhangsiyu/4dgen/CogVideo/finetune/datasets/__init__.py)
[rank3]: Traceback (most recent call last):
[rank3]:   File "/mnt/petrelfs/zhangsiyu/4dgen/CogVideo/finetune/train.py", line 19, in <module>
[rank3]:     main()
[rank3]:   File "/mnt/petrelfs/zhangsiyu/4dgen/CogVideo/finetune/train.py", line 15, in main
[rank3]:     trainer.fit()
[rank3]:   File "/mnt/petrelfs/zhangsiyu/4dgen/CogVideo/finetune/trainer.py", line 673, in fit
[rank3]:     self.prepare_dataset()
[rank3]:   File "/mnt/petrelfs/zhangsiyu/4dgen/CogVideo/finetune/trainer.py", line 204, in prepare_dataset
[rank3]:     tmp_data_loader = self.accelerator.prepare_data_loader(tmp_data_loader)
[rank3]:   File "/mnt/petrelfs/zhangsiyu/miniconda3/envs/cogvideox/lib/python3.10/site-packages/accelerate/accelerator.py", line 2715, in prepare_data_loader
[rank3]:     prepared_data_loader = prepare_data_loader(
[rank3]:   File "/mnt/petrelfs/zhangsiyu/miniconda3/envs/cogvideox/lib/python3.10/site-packages/accelerate/data_loader.py", line 1205, in prepare_data_loader
[rank3]:     from datasets import IterableDataset as DatasetsIterableDataset
[rank3]: ImportError: cannot import name 'IterableDataset' from 'datasets' (/mnt/petrelfs/zhangsiyu/4dgen/CogVideo/finetune/datasets/__init__.py)
[rank0]: Traceback (most recent call last):
[rank0]:   File "/mnt/petrelfs/zhangsiyu/4dgen/CogVideo/finetune/train.py", line 19, in <module>
[rank0]:     main()
[rank0]:   File "/mnt/petrelfs/zhangsiyu/4dgen/CogVideo/finetune/train.py", line 15, in main
[rank0]:     trainer.fit()
[rank0]:   File "/mnt/petrelfs/zhangsiyu/4dgen/CogVideo/finetune/trainer.py", line 673, in fit
[rank0]:     self.prepare_dataset()
[rank0]:   File "/mnt/petrelfs/zhangsiyu/4dgen/CogVideo/finetune/trainer.py", line 204, in prepare_dataset
[rank0]:     tmp_data_loader = self.accelerator.prepare_data_loader(tmp_data_loader)
[rank0]:   File "/mnt/petrelfs/zhangsiyu/miniconda3/envs/cogvideox/lib/python3.10/site-packages/accelerate/accelerator.py", line 2715, in prepare_data_loader
[rank0]:     prepared_data_loader = prepare_data_loader(
[rank0]:   File "/mnt/petrelfs/zhangsiyu/miniconda3/envs/cogvideox/lib/python3.10/site-packages/accelerate/data_loader.py", line 1205, in prepare_data_loader
[rank0]:     from datasets import IterableDataset as DatasetsIterableDataset
[rank0]: ImportError: cannot import name 'IterableDataset' from 'datasets' (/mnt/petrelfs/zhangsiyu/4dgen/CogVideo/finetune/datasets/__init__.py)
[rank5]: Traceback (most recent call last):
[rank5]:   File "/mnt/petrelfs/zhangsiyu/4dgen/CogVideo/finetune/train.py", line 19, in <module>
[rank5]:     main()
[rank5]:   File "/mnt/petrelfs/zhangsiyu/4dgen/CogVideo/finetune/train.py", line 15, in main
[rank5]:     trainer.fit()
[rank5]:   File "/mnt/petrelfs/zhangsiyu/4dgen/CogVideo/finetune/trainer.py", line 673, in fit
[rank5]:     self.prepare_dataset()
[rank5]:   File "/mnt/petrelfs/zhangsiyu/4dgen/CogVideo/finetune/trainer.py", line 204, in prepare_dataset
[rank5]:     tmp_data_loader = self.accelerator.prepare_data_loader(tmp_data_loader)
[rank5]:   File "/mnt/petrelfs/zhangsiyu/miniconda3/envs/cogvideox/lib/python3.10/site-packages/accelerate/accelerator.py", line 2715, in prepare_data_loader
[rank5]:     prepared_data_loader = prepare_data_loader(
[rank5]:   File "/mnt/petrelfs/zhangsiyu/miniconda3/envs/cogvideox/lib/python3.10/site-packages/accelerate/data_loader.py", line 1205, in prepare_data_loader
[rank5]:     from datasets import IterableDataset as DatasetsIterableDataset
[rank5]: ImportError: cannot import name 'IterableDataset' from 'datasets' (/mnt/petrelfs/zhangsiyu/4dgen/CogVideo/finetune/datasets/__init__.py)
[rank4]: Traceback (most recent call last):
[rank4]:   File "/mnt/petrelfs/zhangsiyu/4dgen/CogVideo/finetune/train.py", line 19, in <module>
[rank4]:     main()
[rank4]:   File "/mnt/petrelfs/zhangsiyu/4dgen/CogVideo/finetune/train.py", line 15, in main
[rank4]:     trainer.fit()
[rank4]:   File "/mnt/petrelfs/zhangsiyu/4dgen/CogVideo/finetune/trainer.py", line 673, in fit
[rank4]:     self.prepare_dataset()
[rank4]:   File "/mnt/petrelfs/zhangsiyu/4dgen/CogVideo/finetune/trainer.py", line 204, in prepare_dataset
[rank4]:     tmp_data_loader = self.accelerator.prepare_data_loader(tmp_data_loader)
[rank4]:   File "/mnt/petrelfs/zhangsiyu/miniconda3/envs/cogvideox/lib/python3.10/site-packages/accelerate/accelerator.py", line 2715, in prepare_data_loader
[rank4]:     prepared_data_loader = prepare_data_loader(
[rank4]:   File "/mnt/petrelfs/zhangsiyu/miniconda3/envs/cogvideox/lib/python3.10/site-packages/accelerate/data_loader.py", line 1205, in prepare_data_loader
[rank4]:     from datasets import IterableDataset as DatasetsIterableDataset
[rank4]: ImportError: cannot import name 'IterableDataset' from 'datasets' (/mnt/petrelfs/zhangsiyu/4dgen/CogVideo/finetune/datasets/__init__.py)
[rank1]: Traceback (most recent call last):
[rank1]:   File "/mnt/petrelfs/zhangsiyu/4dgen/CogVideo/finetune/train.py", line 19, in <module>
[rank1]:     main()
[rank1]:   File "/mnt/petrelfs/zhangsiyu/4dgen/CogVideo/finetune/train.py", line 15, in main
[rank1]:     trainer.fit()
[rank1]:   File "/mnt/petrelfs/zhangsiyu/4dgen/CogVideo/finetune/trainer.py", line 673, in fit
[rank1]:     self.prepare_dataset()
[rank1]:   File "/mnt/petrelfs/zhangsiyu/4dgen/CogVideo/finetune/trainer.py", line 204, in prepare_dataset
[rank1]:     tmp_data_loader = self.accelerator.prepare_data_loader(tmp_data_loader)
[rank1]:   File "/mnt/petrelfs/zhangsiyu/miniconda3/envs/cogvideox/lib/python3.10/site-packages/accelerate/accelerator.py", line 2715, in prepare_data_loader
[rank1]:     prepared_data_loader = prepare_data_loader(
[rank1]:   File "/mnt/petrelfs/zhangsiyu/miniconda3/envs/cogvideox/lib/python3.10/site-packages/accelerate/data_loader.py", line 1205, in prepare_data_loader
[rank1]:     from datasets import IterableDataset as DatasetsIterableDataset
[rank1]: ImportError: cannot import name 'IterableDataset' from 'datasets' (/mnt/petrelfs/zhangsiyu/4dgen/CogVideo/finetune/datasets/__init__.py)
[rank0]:[W120 19:32:49.986200948 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
W0120 19:32:54.204000 92925 site-packages/torch/distributed/elastic/multiprocessing/api.py:908] Sending process 99449 closing signal SIGTERM
W0120 19:32:54.209000 92925 site-packages/torch/distributed/elastic/multiprocessing/api.py:908] Sending process 99451 closing signal SIGTERM
W0120 19:32:54.209000 92925 site-packages/torch/distributed/elastic/multiprocessing/api.py:908] Sending process 99452 closing signal SIGTERM
W0120 19:32:54.209000 92925 site-packages/torch/distributed/elastic/multiprocessing/api.py:908] Sending process 99453 closing signal SIGTERM
W0120 19:32:54.209000 92925 site-packages/torch/distributed/elastic/multiprocessing/api.py:908] Sending process 99454 closing signal SIGTERM
W0120 19:32:54.209000 92925 site-packages/torch/distributed/elastic/multiprocessing/api.py:908] Sending process 99455 closing signal SIGTERM
W0120 19:32:54.209000 92925 site-packages/torch/distributed/elastic/multiprocessing/api.py:908] Sending process 99456 closing signal SIGTERM
E0120 19:32:54.518000 92925 site-packages/torch/distributed/elastic/multiprocessing/api.py:882] failed (exitcode: 1) local_rank: 1 (pid: 99450) of binary: /mnt/petrelfs/zhangsiyu/miniconda3/envs/cogvideox/bin/python3.10
Traceback (most recent call last):
  File "/mnt/petrelfs/zhangsiyu/miniconda3/envs/cogvideox/bin/accelerate", line 7, in <module>
    sys.exit(main())
  File "/mnt/petrelfs/zhangsiyu/miniconda3/envs/cogvideox/lib/python3.10/site-packages/accelerate/commands/accelerate_cli.py", line 50, in main
    args.func(args)
  File "/mnt/petrelfs/zhangsiyu/miniconda3/envs/cogvideox/lib/python3.10/site-packages/accelerate/commands/launch.py", line 1266, in launch_command
    deepspeed_launcher(args)
  File "/mnt/petrelfs/zhangsiyu/miniconda3/envs/cogvideox/lib/python3.10/site-packages/accelerate/commands/launch.py", line 952, in deepspeed_launcher
    distrib_run.run(args)
  File "/mnt/petrelfs/zhangsiyu/miniconda3/envs/cogvideox/lib/python3.10/site-packages/torch/distributed/run.py", line 927, in run
    elastic_launch(
  File "/mnt/petrelfs/zhangsiyu/miniconda3/envs/cogvideox/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 156, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/mnt/petrelfs/zhangsiyu/miniconda3/envs/cogvideox/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 293, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
train.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2026-01-20_19:32:54
  host      : HOST-10-140-60-134
  rank      : 1 (local_rank: 1)
  exitcode  : 1 (pid: 99450)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
srun: error: HOST-10-140-60-134: task 0: Exited with exit code 1
